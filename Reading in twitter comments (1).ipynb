{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy, pandas as pd, numpy as np, json, re, seaborn as sns, datetime, time, requests\n",
    "from textblob import TextBlob\n",
    "from datetime import timedelta\n",
    "#from TwitterAPI import TwitterAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Twitter Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "consumer_key = 'sW0oAfGFGSWUHbOGv5JhvpCiW'\n",
    "consumer_secret = 'V6lRbVNA7WKhOu71Io5QyHAr0x0GazuHDNDkykaAeuJjxbNSea'\n",
    "access_token = '250349566-Q5lBnCb2TQwUGrroNVQgJ2HHkkZPxgyBJQWZYLWM'\n",
    "access_token_secret = 'NjoCJw62fcxh2t8JFQmA6jxuwLLE6904o6ETOgq02MlzY'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that returns how many minutes between two time stamp points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalminutes(t1, t2):\n",
    "    diff = t2-t1\n",
    "    try:\n",
    "        mins = diff.hours*60+diff.minutes+diff.seconds/60\n",
    "    except : \n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        mins = diff.minutes+diff.seconds/60\n",
    "    except : \n",
    "        mins = diff.seconds/60\n",
    "    return round(mins,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the twitter handles of US members of congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "legisl = requests.get(\"https://theunitedstates.io/congress-legislators/legislators-social-media.json\")\n",
    "legisl_dict = json.loads(legisl.text)\n",
    "users = list()\n",
    "for row in legisl_dict:\n",
    "    try:\n",
    "        users.append(row['social']['twitter'])\n",
    "    except: \n",
    "        time.sleep(10**-6) #this code is in case they don't have a twitter. I maybe could just leave it blank but do need to have an except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the full code to retrieve the data. The cells below test parts of the code a piece at a time. This puts it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = dict()\n",
    "for user in users:\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    #this first block of code reads in the recent tweets from the user\n",
    "    user_tweets = list(api.user_timeline(user, count=200, include_rts=False, exclude_replies=True, tweet_mode=\"extended\"))\n",
    "    time.sleep(1)\n",
    "    length = len(user_tweets)-1\n",
    "    lasttweet = user_tweets[length]\n",
    "    lastdate = lasttweet.created_at \n",
    "    lastid = lasttweet.id\n",
    "    tweets_list = list()\n",
    "    \n",
    "    #this block reads in more if they have more than 200 in the last week\n",
    "    while lastdate> (now - timedelta(days=7)): \n",
    "        newtweets = api.user_timeline(user, count=200, include_rts=False, exclude_replies=True, max_id=lastid)\n",
    "        length = len(newtweets)-1\n",
    "        lastid=newtweets[length].id\n",
    "        tweet_list = tweet_list+newtweets\n",
    "        time.sleep(1)    \n",
    "    user_tweets=user_tweets+tweet_list\n",
    "    \n",
    "    #this block deletes any extra tweets that aren't in the last 7 days\n",
    "    todelete = list()\n",
    "    for x in range(0, len(user_tweets)):\n",
    "            if user_tweets[x].created_at < now-timedelta(days=7):\n",
    "                todelete.append(x)\n",
    "    user_tweets = user_tweets[0:min(todelete)]\n",
    "\n",
    "    #this section of the code takes each tweet and tries to find comments\n",
    "    touser = \"to@\"+user\n",
    "    all_usertweets = dict()\n",
    "    for tweet in range(0,len(user_tweets)):\n",
    "        tomatch = user_tweets[tweet].id\n",
    "        totweets = api.search(q= touser, count=100, \n",
    "                              tweet_mode=\"extended\", result_type=\"recent\")\n",
    "        comments = list()\n",
    "        for x in range(0,len(totweets)):\n",
    "            if totweets[x].in_reply_to_status_id==tomatch:\n",
    "                comments.append(totweets[x].full_text)\n",
    "        if totweets[len(totweets)-1].id>tomatch:\n",
    "            while len(comments)<100 and totweets[0].id>tomatch:\n",
    "                time1 = datetime.datetime.now()\n",
    "                reference = totweets[len(totweets)-1].id\n",
    "                totweets = api.search(q= touser, count=100, \n",
    "                                      tweet_mode=\"extended\", max_id=reference, result_type=\"recent\")\n",
    "                for x in range(0,len(totweets)):\n",
    "                    if totweets[x].in_reply_to_status_id==tomatch:\n",
    "                        comments.append(totweets[x].full_text)  \n",
    "                time2 = datetime.datetime.now()\n",
    "                delay = (time2-time1).seconds+(10**-6)*(time2-time1).microseconds\n",
    "                time.sleep(5-delay) #set this to make sure we don't go over twitter's limit  \n",
    "                    \n",
    "    #this section puts the text and other meta-data with the comments and puts them together in a dictionary.\n",
    "        thistweetframe = dict()\n",
    "        thistweetframe['text'] = user_tweets[tweet].full_text\n",
    "        thistweetframe['Retweets'] = user_tweets[tweet].retweet_count\n",
    "        thistweetframe['Likes'] = user_tweets[tweet].favorite_count\n",
    "        thistweetframe['Length'] = len(user_tweets[tweet].full_text)\n",
    "        thistweetframe['Date'] = user_tweets[tweet].created_at\n",
    "        thistweetframe['comments'] = comments #later we will add other elements of the tweet to the dictionary\n",
    "        all_usertweets[tweet] = thistweetframe\n",
    "    \n",
    "    all_users[user] = all_usertweets\n",
    "    time_end = datetime.datetime.now()\n",
    "    print(\"{} took {} minutes\".format(user,totalminutes(now, time_end)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
